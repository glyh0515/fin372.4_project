{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioDB():\n",
    "    \n",
    "    # Maintenance margin requirement for each asset (as a fraction of absolute market value)\n",
    "    maint_margin_frac = 0.5\n",
    "    \n",
    "    # Do not modify these\n",
    "    cash_security_id = 'cash'     # Security identifier for cash\n",
    "    ret_tallied_dates = set()     # Set of dates we've already tallied\n",
    "    \n",
    "    \n",
    "    # Initialization function (aka constructor) that runs whenever you create a new PortfolioDB() elsewhere, for example: portfolio_db = PortfolioDB()\n",
    "    def __init__(self) :\n",
    "        # Create three main DataFrames: positions_df, trades_df, account_history_df\n",
    "\n",
    "        #####################################################################\n",
    "        # positions_df:\n",
    "        #\n",
    "        # A snapshot of all positions currently in the portfolio, lumping them togeter by identifier\n",
    "        # so if you bought 100 shares ABC on 11/1 and another 150 shares on 12/1, and have made no other trades, current_portfolio will have a row with\n",
    "        # identifier = ABC, position = 250\n",
    "        #\n",
    "        # Meant to match what you observe on your brokerage account screen\n",
    "        #\n",
    "        # In backtests, we keep track of this ourselves\n",
    "        # In live trading, this will be pulled from the brokerage\n",
    "        #       \n",
    "        self.positions_df = self.empty_positions_df()\n",
    "        #####################################################################\n",
    "        \n",
    "        \n",
    "        #####################################################################\n",
    "        # trades_df\n",
    "        #\n",
    "        # An archive of all trades ever made as part of this strategy\n",
    "        # Each row is a trade, defined as a round-trip transaction for a specific security, wherein you:\n",
    "        # - Buy/sell to \"open\" the trade at time t1\n",
    "        # - Sell/buy to \"close\" the trade at some time t2 > t1\n",
    "        # \n",
    "        # Here we specify that trades_df records the prices, quantities, and timings of trades, but\n",
    "        # users can add columns to this DataFrame for inputs that let to the trade being opened, details of the transaction, etc\n",
    "        #\n",
    "        # index is an automatically-generated integer identifier\n",
    "        self.trades_df = self.empty_trades_df()\n",
    "        #####################################################################\n",
    "        \n",
    "        #####################################################################\n",
    "        # account_history_df\n",
    "        #\n",
    "        # An archive of account-level variables for each time unit (usually day) in the backtest\n",
    "        # or recorded as often as you want during live trading\n",
    "        self.account_history_df = self.empty_account_history_df()\n",
    "        #####################################################################\n",
    "\n",
    "    # Creates an empty positions_df with all the right column types\n",
    "    def empty_positions_df(self):\n",
    "        return pd.DataFrame({'security_id': pd.Series([], dtype='object'), #security identifier such as ticker or permno or optionid whatever unique identifier for the position\n",
    "                             'quantity': pd.Series([], dtype='float'), # number of units in portfolio, can be positive or negative. Never 0 (zero positions removed from this DataFrame unless its cash)\n",
    "                             'average_cost': pd.Series([], dtype='float'), # average cost of units in portfolio\n",
    "                             'current_price': pd.Series([], dtype='float') # current price of security\n",
    "                            })\n",
    "    \n",
    "    # Creates an empty trades_df with all the right column types\n",
    "    def empty_trades_df(self):\n",
    "        return pd.DataFrame({'security_id': pd.Series([], dtype='object'), # ticker or permno or optionid whatever unique identifier for the position\n",
    "                             'quantity': pd.Series([], dtype='float'), # number of units traded. positive = buy, negative = sell\n",
    "                             'open_datetime': pd.Series([], dtype='datetime64[ns]'), # datetime on which the trade was opened\n",
    "                             'open_average_price': pd.Series([], dtype='float'), # average open price of the units in the trade                                              \n",
    "                             'close_datetime': pd.Series([], dtype='datetime64[ns]'), # datetime on which the trade was closed\n",
    "                             'close_average_price': pd.Series([], dtype='float') # average close price of the units in the traade\n",
    "                            })\n",
    "    \n",
    "    # Creates an empty account_history_df with all the right column types\n",
    "    def empty_account_history_df(self):\n",
    "        return pd.DataFrame({'datetime': pd.Series([], dtype='datetime64[ns]'), # datetime on which the account data was recorded\n",
    "                             'nav': pd.Series([], dtype='float'), # account net asset value\n",
    "                             'cash_position': pd.Series([], dtype='float'), # account cash position\n",
    "                             'margin_requirement': pd.Series([], dtype='float') # account margin requirement\n",
    "                            })\n",
    "        \n",
    "    # Adds the passed amount of cash to the positions_df\n",
    "    def add_cash(self,cash_to_add):        \n",
    "        if( not self.positions_df['security_id'].str.contains(self.cash_security_id).any() ):\n",
    "            # Append is being deprecated, so we need to switch to concat\n",
    "            self.positions_df = pd.concat([ self.positions_df, pd.DataFrame({'security_id':[self.cash_security_id],'quantity':[0], 'average_cost':[1], 'current_price':[1]})])\n",
    "             # self.positions_df = self.positions_df.append(pd.DataFrame({'security_id':[self.cash_security_id],'quantity':[0], 'average_cost':[1], 'current_price':[1]}))\n",
    "                \n",
    "\n",
    "        self.positions_df.loc[self.positions_df['security_id']==self.cash_security_id,'quantity'] += cash_to_add\n",
    "        \n",
    "    # adds new trade rows into the trades_df, and updates positions_df accordingly\n",
    "    # passed open_trades_df must be a Pandas DataFrame with columns 'security_id','open_datetime','quantity' and 'open_average_price' variables.\n",
    "    # open_trades_df can also have custom data in whatever additional columns you want\n",
    "    # So for example, you can create a single trade where you opened a short position for 200 shares of stock with security_id=12345 on 2005-02-25 in the following way:\n",
    "    #    trades pd.DataFrame({'security_id':[12345], 'open_datetime':[np.datetime64('2005-01-23')], 'quantity':[-200], 'open_average_price':[39.25], 'custom_data':[1.234]})\n",
    "    # where custom_data is some custom column you want to add\n",
    "    def open_trades(self,open_trades_df):     \n",
    "        # trades must have columns for security_id, open_datetime, quantity, and open_average_price (cannot correct, raise error)\n",
    "        validate_df_columns(open_trades_df,['security_id','open_datetime','quantity','open_average_price'])\n",
    "        \n",
    "        # security_id column must have type object (can correct)\n",
    "        if open_trades_df['security_id'].dtype != object:            \n",
    "            open_trades_df['security_id'] = open_trades_df['security_id'].astype(object)\n",
    "                \n",
    "        # lump together all trades with the same security_id and open_datetime as one\n",
    "        open_trades_df = groupby_agg_wavg(df=open_trades_df, group_by=['security_id','open_datetime'],\n",
    "                                          default_method='first',\n",
    "                                          wavg_columns=['open_average_price'],\n",
    "                                          wavg_weight='quantity')\n",
    "\n",
    "        # Append to existing trades_df\n",
    "        # Append is being deprecated, so we need to switch to concat\n",
    "        # self.trades_df = self.trades_df.append(open_trades_df)\n",
    "        self.trades_df = pd.concat([ self.trades_df, open_trades_df ])\n",
    "        \n",
    "        # Each trade adds -open_average_price*quantity to the cash balance\n",
    "        self.add_cash( -(open_trades_df['open_average_price']*open_trades_df['quantity']).sum() )\n",
    "                                                 \n",
    "        # positions impact of this is to add quantity to position for security id and adjust average_cost \n",
    "            \n",
    "        # extract the columns we need for positions_df from the trades data\n",
    "        trades_position_df = open_trades_df.loc[:,['security_id', 'quantity', 'open_average_price']] \n",
    "        trades_position_df = trades_position_df.rename(columns={'open_average_price':'average_cost'}) \n",
    "            \n",
    "        self.append_positions(trades_position_df)\n",
    "                        \n",
    "        self.remove_zero_positions() \n",
    "        \n",
    "    # closes existing trade rows in the trades_df, and updates positions_df accordingly\n",
    "    # passed close_trades_df must be a Pandas DataFrame with columns 'security_id', 'open_datetime', close_datetime', and 'close_average_price' variables.\n",
    "    # security_id and open_datetime will be used to identify the trade in the current trades_df to close\n",
    "    # close_trades_df can also have custom data in whatever additional columns you want\n",
    "    # So for example, you can close trade where you opened a short position for 200 shares of stock with security_id=12345 on 2005-02-25 in the following way:\n",
    "    #    close_trades_df = pd.DataFrame({'security_id':[12345], 'open_datetime':[np.datetime64('2005-01-23')], 'close_datetime':[np.datetime64('2005-08-09')], 'close_average_price':[np.datetime64('2005-08-09')], 'close_custom_data':[1.234]})\n",
    "    # where close_custom_data is some custom column you want to add\n",
    "    def close_trades(self,close_trades_df):\n",
    "        # trades must have columns for security_id, open_datetime, close_datetime, and close_average_price (cannot correct, raise error)\n",
    "        validate_df_columns(close_trades_df,['security_id','open_datetime','close_datetime','close_average_price'])\n",
    "\n",
    "        # find corresponding trades in trades_df\n",
    "        # if we somehow have multiple for a given security_idk/open_datetime pair, go with the first \n",
    "        close_trades_df = close_trades_df.groupby(['security_id','open_datetime']).agg('first').reset_index() \n",
    "        close_trades_df = close_trades_df.astype({'security_id':'object', 'open_datetime':'datetime64[ns]'})\n",
    "        \n",
    "        self.trades_df = self.trades_df.merge(close_trades_df, on=['security_id','open_datetime'], suffixes=('','_cldf'), how='left')\n",
    "\n",
    "        # use the close_datetime_cldf column to add a new view indicating whether each trade was just closed\n",
    "        just_closed = self.trades_df.loc[:,'close_datetime_cldf'].notnull()\n",
    "    \n",
    "        # use the _cldf suffix values for close_datetime and close_average_price\n",
    "        self.trades_df.loc[just_closed,'close_datetime'] = pd.to_datetime(self.trades_df.loc[just_closed,'close_datetime_cldf'])\n",
    "        self.trades_df.loc[just_closed,'close_average_price'] = self.trades_df.loc[just_closed,'close_average_price_cldf']\n",
    "        \n",
    "        # drop the _cldf suffix values\n",
    "        self.trades_df = self.trades_df.loc[:,~self.trades_df.columns.str.endswith('_cldf')]\n",
    "\n",
    "        # add cash\n",
    "        self.add_cash( (self.trades_df.loc[just_closed,'close_average_price']*self.trades_df.loc[just_closed,'quantity']).sum() )\n",
    "        \n",
    "        # now update positions\n",
    "        # create a new positions row for each of the closed trades\n",
    "        trades_position_df = self.trades_df.loc[just_closed,['security_id', 'quantity', 'open_average_price']]\n",
    "        trades_position_df = trades_position_df.rename(columns={'open_average_price':'average_cost'}) \n",
    "        trades_position_df['quantity'] = trades_position_df['quantity']*(-1) # negate quantity because we are closing\n",
    "        \n",
    "        self.append_positions(trades_position_df)     \n",
    "        \n",
    "        self.remove_zero_positions() \n",
    "    \n",
    "    # Update prices of everything in portfolio_df using passed price_df\n",
    "    def update_prices(self,price_df):\n",
    "        # price_df must have columns for security_id, prc, and ret, and must have only one date (cannot correct, raise error)\n",
    "        validate_df_columns(price_df,['security_id','prc','ret'])\n",
    "        validate_all_values_same(price_df['date'])\n",
    "                \n",
    "        # security_id column must have type object (can correct)\n",
    "        if price_df.loc[:,'security_id'].dtype != object:            \n",
    "            price_df['security_id'] = price_df.loc[:,'security_id'].astype(object)\n",
    "        \n",
    "        self.positions_df = self.positions_df.merge(price_df.loc[:,['security_id','prc','ret']],on='security_id',how='left')\n",
    "        # set missing returns to zero, otherwise we drop positions from our NAV calculation\n",
    "        self.positions_df.loc[:,'ret'] = self.positions_df.loc[:,'ret'].fillna(0)\n",
    "                \n",
    "        self.positions_df.loc[:,'lagged_price'] = self.positions_df.loc[:,'current_price']\n",
    "        \n",
    "        # update current_prices to match actual data\n",
    "        self.positions_df.loc[:,'current_price'] = np.where(self.positions_df.loc[:,'prc'].notnull(),\n",
    "                                                            self.positions_df.loc[:,'prc'],\n",
    "                                                            self.positions_df.loc[:,'current_price'])\n",
    "        \n",
    "        # Replace na current_prices with average_cost\n",
    "        null_current_price = self.positions_df.loc[:,'current_price'].isna()\n",
    "        self.positions_df.loc[null_current_price,'current_price'] = self.positions_df.loc[null_current_price,'average_cost']\n",
    "        \n",
    "        # First date is fine since they should all be the same\n",
    "        date = price_df.loc[:,'date'].iloc[0]\n",
    "        \n",
    "        # we only want to tally returns once per date, so check that we haven't already\n",
    "        if( date not in self.ret_tallied_dates ):\n",
    "            # multiply lagged_price by returne to get a hypothetical price\n",
    "            self.positions_df.loc[:,'ret_based_price'] = self.positions_df.loc[:,'lagged_price']*(self.positions_df.loc[:,'ret']+1)\n",
    "            \n",
    "            # update quantities so that ret_based_price*old_quantity = current_price*new_quantity\n",
    "            self.positions_df.loc[:,'quantity_multiple'] = self.positions_df.loc[:,'ret_based_price'] / self.positions_df.loc[:,'current_price']\n",
    "            self.positions_df.loc[:,'quantity'] = self.positions_df.loc[:,'quantity']*self.positions_df.loc[:,'quantity_multiple']\n",
    "            \n",
    "            # No longer need ret-based_price\n",
    "            self.positions_df = self.positions_df.drop(columns=['ret_based_price'])\n",
    "            \n",
    "            # update quantities of open trades as well\n",
    "            still_open = self.trades_df.loc[:,'close_datetime'].isna() \n",
    "            \n",
    "            if( not still_open.empty ):  \n",
    "                self.trades_df = self.trades_df.merge(self.positions_df.loc[:,['security_id','quantity_multiple']],\n",
    "                                                      on=['security_id'],\n",
    "                                                      suffixes=('','_posdf'),\n",
    "                                                      how='left')\n",
    "                self.trades_df.loc[still_open,'quantity'] = self.trades_df.loc[still_open,'quantity']*self.trades_df.loc[still_open,'quantity_multiple']          \n",
    "            \n",
    "                # drop the _posdf suffix values\n",
    "                self.trades_df = self.trades_df.loc[:,~self.trades_df.columns.str.endswith('_posdf')]\n",
    "\n",
    "                # drop the extra columns\n",
    "                self.trades_df = self.trades_df.drop(columns=['quantity_multiple'])                \n",
    "            # end of if\n",
    "            \n",
    "            self.ret_tallied_dates.add(date)\n",
    "        # end of if\n",
    "        \n",
    "        self.positions_df = self.positions_df.drop(columns=['prc','lagged_price','ret'])\n",
    "    \n",
    "    # Removes any positions in with zero quantity from the positions_df\n",
    "    # Due to rounding errors, we may not have quantity exactly equal to zero, so we remove when the price*quantity is bigger than 0.1 cents\n",
    "    def remove_zero_positions(self): \n",
    "        # Find \"price\" as current_price, if we have one, or average_cost if we don't\n",
    "        prices = np.where( self.positions_df.loc[:,'current_price'].notnull(),\n",
    "                          self.positions_df.loc[:,'current_price'],\n",
    "                          self.positions_df.loc[:,'average_cost'] )\n",
    "        # Be sure also to never remove the cash entry even when it has 0 quantity\n",
    "        self.positions_df = self.positions_df[ (np.abs(self.positions_df.loc[:,'quantity']*prices) > 1.0E-5) |\n",
    "                                               (self.positions_df.loc[:,'security_id'] == 'cash') ]\n",
    "        \n",
    "    # Add new row to account_history_df based on current portfolio and passed datetime, after updating prices using passed price_df    \n",
    "    def record_account_data(self,price_df,datetime):\n",
    "        self.update_prices(price_df)\n",
    "        # Append is being deprecated, so we need to switch to concat\n",
    "        # self.account_history_df = self.account_history_df.append(\n",
    "        #     pd.DataFrame({'datetime':[datetime],'nav':[self.current_nav()], 'cash_position':[self.current_cash()], 'margin_requirement':[self.current_margin()]}))\n",
    "        self.account_history_df = pd.concat([ self.account_history_df, \n",
    "                                             pd.DataFrame({'datetime':[datetime],'nav':[self.current_nav()], 'cash_position':[self.current_cash()], 'margin_requirement':[self.current_margin()]}) ] )\n",
    "        \n",
    "    # Returns current NAV    \n",
    "    def current_nav(self):\n",
    "        return (self.positions_df.loc[:,'current_price']*self.positions_df.loc[:,'quantity']).sum()\n",
    "    \n",
    "    # Returns current cash position\n",
    "    def current_cash(self):\n",
    "        # Sum across everything with cash's security_id, just in case there's multiple rows\n",
    "        return self.positions_df.loc[self.positions_df.loc[:,'security_id']==self.cash_security_id,'quantity'].sum()\n",
    "    \n",
    "    # Returns current maintenance margin requirement for the whole portfolio\n",
    "    def current_margin(self):\n",
    "        return self.maint_margin_frac*(np.absolute(self.positions_df['current_price']*self.positions_df['quantity']).sum() - abs(self.current_cash()))\n",
    "\n",
    "    # Append new_positions_df to the positions_df\n",
    "    # new_positions can potentially have multiple rows with the same security_id, and will often have rows with security_id already in positions_df\n",
    "    # problem is that positions_df is supposed to have only one row per security_id\n",
    "    # so to merge positions_df with trade_positions, we need to first append the new positions, then group by security id\n",
    "    def append_positions(self,new_position_df):\n",
    "        # Append, which creates duplicates\n",
    "        # Append is being deprecated, so we need to switch to concat\n",
    "        # self.positions_df = self.positions_df.append(new_position_df) \n",
    "        self.positions_df = pd.concat([ self.positions_df, new_position_df ])\n",
    "        \n",
    "        # group and aggregate using weighted average\n",
    "        self.positions_df = groupby_agg_wavg(df=self.positions_df, group_by='security_id', default_method='last', wavg_columns=['average_cost'], wavg_weight='quantity')\n",
    "        \n",
    "        # Fix average_cost in case it's tiny or negative due to bad weighted averaging\n",
    "        self.positions_df.loc[ self.positions_df.loc[:,'average_cost'] < 0.1, 'average_cost' ] = np.NaN\n",
    "        \n",
    "        \n",
    "###################################################################\n",
    "# Helper methods, do not modify\n",
    "###################################################################\n",
    "\n",
    "# Groups passed df by the group_by columns and aggregates using:\n",
    "#   - default_method, unless:\n",
    "#   - specified_methods, a dictionary mapping column names to methods, contains the column name\n",
    "#   - the column is contained in wavg_columns, which aggregaes using a custom \"weighted average\" aggregation\n",
    "#       - if we are doing weighted average aggregation, wavg_weight is the name of the column used for weighting\n",
    "def groupby_agg_wavg(df, group_by, default_method='sum', specified_methods={}, wavg_columns=[], wavg_weight=''):    \n",
    "    starting_col_names = df.columns\n",
    "    starting_col_types = df.dtypes\n",
    "\n",
    "    df2 = df.copy() # don't want to modify original passed in\n",
    "    \n",
    "    # create dictionary that will map column names to functions used for aggregation\n",
    "    method_dict = dict.fromkeys(df2.columns,default_method)  # start with using default_method for all columns\n",
    "    method_dict.update(specified_methods) # update with any specified methods. dict.update modifies the dictionary and does NOT return one\n",
    "    \n",
    "    # create columns for weight*var \n",
    "    temp_columns = ['wtimes_' + s for s in wavg_columns] # name temp columns wtimes_<original_name>\n",
    "    df2[temp_columns] = df2[wavg_columns].multiply(df2[wavg_weight], axis='index') # multiply by weights\n",
    "    method_dict.update( dict.fromkeys(temp_columns,'sum') ) # want to sum these cols when we aggregate\n",
    "    method_dict[wavg_weight] = 'sum' # need to sum the wavg weight\n",
    "    \n",
    "    # run actual groupby, resetting index\n",
    "    df2 = df2.groupby(group_by).agg(method_dict).reset_index(drop=True)\n",
    "    \n",
    "    # use weight*var sum columns to go back to actual weighted average\n",
    "    df2[wavg_columns] = df2[temp_columns].divide(df2[wavg_weight], axis='index')\n",
    "    \n",
    "    # go back to original column names in correct order\n",
    "    df2 = df2[starting_col_names]\n",
    "    df2 = df2.astype(starting_col_types)\n",
    "    \n",
    "    return df2 \n",
    "\n",
    "# Validates the passed dataframe has the columns in passed array required_columns\n",
    "# If not, it raises a ValueError\n",
    "def validate_df_columns(df,required_columns):\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError('DataFrame missing required column named \\'' + col + '\\'' )\n",
    "\n",
    "# Validates all the values in the passed series are the same\n",
    "# If not, it raises a ValueError\n",
    "def validate_all_values_same(series):\n",
    "    np_array = series.to_numpy()\n",
    "    if not (np_array[0] == np_array).all():\n",
    "        raise ValueError('Series has multiple unique values but is required to have only one')\n",
    "        \n",
    "# Validates the passed series has no na entries\n",
    "# If it has any, it raises a ValueError\n",
    "def validate_no_missing_values(series):\n",
    "    if( series.isna().sum() > 0 ):\n",
    "        raise ValueError('Series has missing value but is required to have none')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
