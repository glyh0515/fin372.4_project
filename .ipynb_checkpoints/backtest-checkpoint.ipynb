{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\">Quant Platform</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <span style=\"color:green\">*Quant Platform*</span> is a framework for conducting backtests and analyzing the results that can be easily adapted for live trading. Some components needs to be modified or adapted for each strategy being backtested, others can be left alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of components for <span style=\"color:green\">Quant Platform</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Blue</span> components require little to no modification for each strategy tested, while <span style=\"color:orange\">orange</span> components do require modification\n",
    "\n",
    "1. <span style=\"color:orange\">Data Processor</span>\n",
    "    - Loads and merges data\n",
    "    - Provides universe of securities and signals for each date\n",
    "1. <span style=\"color:blue\">Portfolio</span>\n",
    "    - Tracks current portfolio and account balance sheet\n",
    "    - Keeps records of all trades/transactions\n",
    "    - Keeps history of NAV and margin requirements\n",
    "1. <span style=\"color:orange\">Trading Rule</span>\n",
    "    - Decides which trades to make given a universe of securities, signals, and current portfolio\n",
    "1. <span style=\"color:blue\">Executor</span>\n",
    "    - \"Submits\" order either hypothetically using historical data or live to a brokerage\n",
    "    - Calculates or retrieves transaction prices accounting for any liquidity costs\n",
    "1. <span style=\"color:blue\">Statistician</span>\n",
    "    - Looks at results of backtest or live trading and computes statistics ($\\alpha$ etc) as well as informative plots (e.g. NAV and margin over time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo-code for backtest\n",
    "\n",
    "At a high level, our backtest will:\n",
    "\n",
    "1. Tell the **Data Processor** to load all the necessary data\n",
    "1. For each unique date in the data:\n",
    "    1. Get signal (book and market values of equity in this case) and price data for that date from the **Data Processor**\n",
    "    1. Tell **Portfolio** to update prices based on new data\n",
    "    1. Ask **Trading Rule** to decide which trades to make\n",
    "    1. Tell **Executor** to execute the trades\n",
    "    1. Update **Portfolio** to reflect the executed trades\n",
    "1. Tell **Statistician** to summarize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from IPython.display import display, Markdown, Latex, clear_output\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: \"Run\" the notebooks containing definitions of the specifics of the data, strategy, and post-test statistics we want to compute\n",
    "# Think about this as importing these tools but not using them yet\n",
    "\n",
    "# These tools should be changed depending on the strategy you are testing\n",
    "%run dr_data_processor.ipynb\n",
    "%run dr_trading_rule.ipynb\n",
    "\n",
    "# # These tools should remain unchanged across strategies unless you have a good reason to change them\n",
    "%run portfolio_db.ipynb\n",
    "%run backtest_executor.ipynb # if you were live trading a strategy, this would be replace by code that submitted orders etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2: Create the tools we'll need to do the backtest\n",
    "# These can be customized and changed while keeping the rest of this file (the backtest logic) the same\n",
    "\n",
    "# DO edit this code to make sure that the specifics tools you want for this backtest are chosen here\n",
    "\n",
    "# DO NOT edit the names of the variables, only what's assigned to them. So \n",
    "# good: data_processor = MyNewDataProcessor() \n",
    "# bad: my_new_data_processor = MyNewDataProcessor()\n",
    "\n",
    "# Data processor, in charge of loading and doling out data\n",
    "data_processor = DRDataProcessor() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Portfolio database, keeps track of all the trades the backtest makes, the strategy NAV, and the current portfolio as we go through the backtest\n",
    "%run portfolio_db.ipynb\n",
    "portfolio_db = PortfolioDB()\n",
    "\n",
    "# Strategy logic, in charge of choosing trades based on current portfolio and data\n",
    "# This exact code would be used for live trading \n",
    "trading_rule = DRTradingRule(portfolio_db)\n",
    "\n",
    "# Trade executor, in charge of \"executing\" trades the strategy decides on, turning them into transactions and updating the portfolio\n",
    "trade_executor = BacktestExecutor(portfolio_db)\n",
    "\n",
    "# Info about the strategy, used for ex-post statistics and output not the actual backtest\n",
    "strategy_info = {\n",
    "    'brief descriptor': 'drc_lt_dec 0.85 trading cost', \n",
    "    'plot descriptor': 'Equal (drc/lt) Strategy, Equal-Weighted',\n",
    "    'universe': 'Public US equities with accounting data',\n",
    "    'signals': 'DRC/LT ratio, measured at most recent earnings announcement',\n",
    "    'trading rule': 'Buy top 10% by DRC/LT ratio',\n",
    "    'holding period': 'One month',\n",
    "    'periods per year': 12,\n",
    "    'time lag': 'Minimum of {0} days from announcement of montyhly earnings'.format(data_processor.min_accounting_lag),\n",
    "    'output folder name': 'Output'\n",
    "}\n",
    "\n",
    "# Statistician, used to tabulate and plot statistics after the backtest runs\n",
    "%run backtest_statistician.ipynb\n",
    "statistican = BacktestStatistican(portfolio_db,strategy_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2008-07-31: 138.2452376541496 | 69.1226188270748'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Main loop for the backtest\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m udates:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# dataframes for the date\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     signal_df \u001b[38;5;241m=\u001b[39m data_processor\u001b[38;5;241m.\u001b[39msignal_df_for_date(date)\n\u001b[0;32m     14\u001b[0m     price_df \u001b[38;5;241m=\u001b[39m data_processor\u001b[38;5;241m.\u001b[39mprice_df_for_date(date)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Update prices to reflect the new values after however much time has passed\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Need to dot his first each date because the updated prices may affect our trading rule\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28644\\1062788258.py:94\u001b[0m, in \u001b[0;36mDRDataProcessor.signal_df_for_date\u001b[1;34m(self, date)\u001b[0m\n\u001b[0;32m     92\u001b[0m all_past_signal_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignal_df\u001b[38;5;241m.\u001b[39mloc[(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignal_df\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatadate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m date \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mtimedelta64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_accounting_lag,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m)),:]\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# then grab only the latest observation for each permno\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m latest_signal_df \u001b[38;5;241m=\u001b[39m all_past_signal_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpermno\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mlast()\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# now merge with return data and return        \u001b[39;00m\n\u001b[0;32m     97\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m date_price_df\u001b[38;5;241m.\u001b[39mmerge(latest_signal_df,on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpermno\u001b[39m\u001b[38;5;124m'\u001b[39m,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:3376\u001b[0m, in \u001b[0;36mGroupBy.last\u001b[1;34m(self, numeric_only, min_count)\u001b[0m\n\u001b[0;32m   3373\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m   3374\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m(obj))\n\u001b[1;32m-> 3376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_general(\n\u001b[0;32m   3377\u001b[0m     numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   3378\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m   3379\u001b[0m     alias\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3380\u001b[0m     npfunc\u001b[38;5;241m=\u001b[39mlast_compat,\n\u001b[0;32m   3381\u001b[0m )\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1839\u001b[0m, in \u001b[0;36mGroupBy._agg_general\u001b[1;34m(self, numeric_only, min_count, alias, npfunc)\u001b[0m\n\u001b[0;32m   1830\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1831\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_agg_general\u001b[39m(\n\u001b[0;32m   1832\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1837\u001b[0m     npfunc: Callable,\n\u001b[0;32m   1838\u001b[0m ):\n\u001b[1;32m-> 1839\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   1840\u001b[0m         how\u001b[38;5;241m=\u001b[39malias,\n\u001b[0;32m   1841\u001b[0m         alt\u001b[38;5;241m=\u001b[39mnpfunc,\n\u001b[0;32m   1842\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   1843\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m   1844\u001b[0m     )\n\u001b[0;32m   1845\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1929\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   1926\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1929\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgrouped_reduce(array_func)\n\u001b[0;32m   1930\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[0;32m   1931\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1428\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_object:\n\u001b[0;32m   1425\u001b[0m     \u001b[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[0;32m   1426\u001b[0m     \u001b[38;5;66;03m#  while others do not.\u001b[39;00m\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sb \u001b[38;5;129;01min\u001b[39;00m blk\u001b[38;5;241m.\u001b[39m_split():\n\u001b[1;32m-> 1428\u001b[0m         applied \u001b[38;5;241m=\u001b[39m sb\u001b[38;5;241m.\u001b[39mapply(func)\n\u001b[0;32m   1429\u001b[0m         result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m   1430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:366\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    362\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 366\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    368\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1905\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1903\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marray_func\u001b[39m(values: ArrayLike) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m   1904\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1905\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[0;32m   1906\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1907\u001b[0m             values,\n\u001b[0;32m   1908\u001b[0m             how,\n\u001b[0;32m   1909\u001b[0m             axis\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1910\u001b[0m             min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m   1911\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1912\u001b[0m         )\n\u001b[0;32m   1913\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1914\u001b[0m         \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[0;32m   1915\u001b[0m         \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[0;32m   1916\u001b[0m         \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[0;32m   1917\u001b[0m         \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[0;32m   1918\u001b[0m         \u001b[38;5;66;03m# TODO: avoid special casing SparseArray here\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124many\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, SparseArray):\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:816\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[1;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[0;32m    814\u001b[0m ids, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_info\n\u001b[0;32m    815\u001b[0m ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups\n\u001b[1;32m--> 816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cy_op\u001b[38;5;241m.\u001b[39mcython_operation(\n\u001b[0;32m    817\u001b[0m     values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[0;32m    818\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    819\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    820\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    821\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    823\u001b[0m )\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:535\u001b[0m, in \u001b[0;36mWrappedCythonOp.cython_operation\u001b[1;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39m_groupby_op(\n\u001b[0;32m    527\u001b[0m         how\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow,\n\u001b[0;32m    528\u001b[0m         has_dropped_na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_dropped_na,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    533\u001b[0m     )\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_op_ndim_compat(\n\u001b[0;32m    536\u001b[0m     values,\n\u001b[0;32m    537\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    538\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    539\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[0;32m    540\u001b[0m     mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    542\u001b[0m )\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:339\u001b[0m, in \u001b[0;36mWrappedCythonOp._cython_op_ndim_compat\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;66;03m# otherwise we have OHLC\u001b[39;00m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m--> 339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_cython_op(\n\u001b[0;32m    340\u001b[0m     values,\n\u001b[0;32m    341\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m    342\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[0;32m    343\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[0;32m    344\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    345\u001b[0m     result_mask\u001b[38;5;241m=\u001b[39mresult_mask,\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    347\u001b[0m )\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:400\u001b[0m, in \u001b[0;36mWrappedCythonOp._call_cython_op\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    397\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cython_vals(values)\n\u001b[0;32m    398\u001b[0m out_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_out_dtype(values\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m--> 400\u001b[0m result \u001b[38;5;241m=\u001b[39m maybe_fill(np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mout_dtype))\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    402\u001b[0m     counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(ngroups, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Step 3: Run actual backtest\n",
    "# Do NOT edit this cell without a very good reason\n",
    "\n",
    "# Add 100 initial cash to our portfolios\n",
    "portfolio_db.add_cash(100)\n",
    "\n",
    "# Get our list of unique dates\n",
    "udates = data_processor.unique_dates()\n",
    "\n",
    "# Main loop for the backtest\n",
    "for date in udates:\n",
    "    # dataframes for the date\n",
    "    signal_df = data_processor.signal_df_for_date(date)\n",
    "    price_df = data_processor.price_df_for_date(date)\n",
    "\n",
    "    # Update prices to reflect the new values after however much time has passed\n",
    "    # Need to dot his first each date because the updated prices may affect our trading rule\n",
    "    portfolio_db.update_prices(price_df)\n",
    "    \n",
    "    # Ask the trading rule what trades we should make\n",
    "    open_trades_df, close_trades_df = trading_rule.compute_trades(signal_df=signal_df)\n",
    "\n",
    "    # apply dates to trades\n",
    "    open_trades_df.loc[:,'open_datetime'] = date\n",
    "    close_trades_df.loc[:,'close_datetime'] = date\n",
    "\n",
    "    # execute trades\n",
    "    trade_executor.execute_opens(open_trades_df=open_trades_df, price_df=price_df)\n",
    "    trade_executor.execute_closes(close_trades_df=close_trades_df, price_df=price_df)    \n",
    "    \n",
    "    # Record account data for today\n",
    "    portfolio_db.record_account_data(price_df=price_df,datetime=date)\n",
    "    \n",
    "    # Do some fancy output tracking our NAV and margin requirement each day\n",
    "    clear_output(wait=True)\n",
    "    display( np.datetime_as_string(np.datetime64(date), unit='D') + ': ' + str(portfolio_db.current_nav()) + \" | \" + str(portfolio_db.current_margin()))\n",
    "    \n",
    "# Now that the loop is done, tell the statistican to output stats\n",
    "statistican.output_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
