{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\">Quant Platform</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <span style=\"color:green\">*Quant Platform*</span> is a framework for conducting backtests and analyzing the results that can be easily adapted for live trading. Some components needs to be modified or adapted for each strategy being backtested, others can be left alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of components for <span style=\"color:green\">Quant Platform</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Blue</span> components require little to no modification for each strategy tested, while <span style=\"color:orange\">orange</span> components do require modification\n",
    "\n",
    "1. <span style=\"color:orange\">Data Processor</span>\n",
    "    - Loads and merges data\n",
    "    - Provides universe of securities and signals for each date\n",
    "1. <span style=\"color:blue\">Portfolio</span>\n",
    "    - Tracks current portfolio and account balance sheet\n",
    "    - Keeps records of all trades/transactions\n",
    "    - Keeps history of NAV and margin requirements\n",
    "1. <span style=\"color:orange\">Trading Rule</span>\n",
    "    - Decides which trades to make given a universe of securities, signals, and current portfolio\n",
    "1. <span style=\"color:blue\">Executor</span>\n",
    "    - \"Submits\" order either hypothetically using historical data or live to a brokerage\n",
    "    - Calculates or retrieves transaction prices accounting for any liquidity costs\n",
    "1. <span style=\"color:blue\">Statistician</span>\n",
    "    - Looks at results of backtest or live trading and computes statistics ($\\alpha$ etc) as well as informative plots (e.g. NAV and margin over time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo-code for backtest\n",
    "\n",
    "At a high level, our backtest will:\n",
    "\n",
    "1. Tell the **Data Processor** to load all the necessary data\n",
    "1. For each unique date in the data:\n",
    "    1. Get signal (book and market values of equity in this case) and price data for that date from the **Data Processor**\n",
    "    1. Tell **Portfolio** to update prices based on new data\n",
    "    1. Ask **Trading Rule** to decide which trades to make\n",
    "    1. Tell **Executor** to execute the trades\n",
    "    1. Update **Portfolio** to reflect the executed trades\n",
    "1. Tell **Statistician** to summarize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from IPython.display import display, Markdown, Latex, clear_output\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: \"Run\" the notebooks containing definitions of the specifics of the data, strategy, and post-test statistics we want to compute\n",
    "# Think about this as importing these tools but not using them yet\n",
    "\n",
    "# These tools should be changed depending on the strategy you are testing\n",
    "%run dr_data_processor.ipynb\n",
    "%run dr_trading_rule.ipynb\n",
    "\n",
    "# # These tools should remain unchanged across strategies unless you have a good reason to change them\n",
    "%run portfolio_db.ipynb\n",
    "%run backtest_executor.ipynb # if you were live trading a strategy, this would be replace by code that submitted orders etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Dropbox\\\\Jupyter notebooks\\\\Backtest Demo\\\\Data\\\\monthly_returns.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 2: Create the tools we'll need to do the backtest\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# These can be customized and changed while keeping the rest of this file (the backtest logic) the same\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Data processor, in charge of loading and doling out data\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m data_processor \u001b[38;5;241m=\u001b[39m DRDataProcessor()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24800\\235252813.py:19\u001b[0m, in \u001b[0;36mDRDataProcessor.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     16\u001b[0m     \n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Load price data: monthly 1961-2020 sample from CRSP including all public US equities\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# In monthly_returns.csv\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprice_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_folder_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonthly_returns.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Parse the yyyyMMdd int dates into DateTime64\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Based on formatting strings here\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprice_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprice_df\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Dropbox\\\\Jupyter notebooks\\\\Backtest Demo\\\\Data\\\\monthly_returns.csv'"
     ]
    }
   ],
   "source": [
    "# Step 2: Create the tools we'll need to do the backtest\n",
    "# These can be customized and changed while keeping the rest of this file (the backtest logic) the same\n",
    "\n",
    "# DO edit this code to make sure that the specifics tools you want for this backtest are chosen here\n",
    "\n",
    "# DO NOT edit the names of the variables, only what's assigned to them. So \n",
    "# good: data_processor = MyNewDataProcessor() \n",
    "# bad: my_new_data_processor = MyNewDataProcessor()\n",
    "\n",
    "# Data processor, in charge of loading and doling out data\n",
    "data_processor = DRDataProcessor() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Portfolio database, keeps track of all the trades the backtest makes, the strategy NAV, and the current portfolio as we go through the backtest\n",
    "%run portfolio_db.ipynb\n",
    "portfolio_db = PortfolioDB()\n",
    "\n",
    "# Strategy logic, in charge of choosing trades based on current portfolio and data\n",
    "# This exact code would be used for live trading \n",
    "trading_rule = DRTradingRule(portfolio_db)\n",
    "\n",
    "# Trade executor, in charge of \"executing\" trades the strategy decides on, turning them into transactions and updating the portfolio\n",
    "trade_executor = BacktestExecutor(portfolio_db)\n",
    "\n",
    "# Info about the strategy, used for ex-post statistics and output not the actual backtest\n",
    "strategy_info = {\n",
    "    'brief descriptor': 'drc_lt_dec_ew', \n",
    "    'plot descriptor': 'Equal (drc/lt) Strategy, Equal-Weighted',\n",
    "    'universe': 'Public US equities with accounting data',\n",
    "    'signals': 'DRC/LT ratio, measured at most recent earnings announcement',\n",
    "    'trading rule': 'Buy top 10% by DRC/LT ratio',\n",
    "    'holding period': 'One month',\n",
    "    'periods per year': 12,\n",
    "    'time lag': 'Minimum of {0} days from announcement of montyhly earnings'.format(data_processor.min_accounting_lag),\n",
    "    'output folder name': 'Output'\n",
    "}\n",
    "\n",
    "# Statistician, used to tabulate and plot statistics after the backtest runs\n",
    "%run backtest_statistician.ipynb\n",
    "statistican = BacktestStatistican(portfolio_db,strategy_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 3: Run actual backtest\n",
    "# Do NOT edit this cell without a very good reason\n",
    "\n",
    "# Add 100 initial cash to our portfolios\n",
    "portfolio_db.add_cash(100)\n",
    "\n",
    "# Get our list of unique dates\n",
    "udates = data_processor.unique_dates()\n",
    "\n",
    "# Main loop for the backtest\n",
    "for date in udates:\n",
    "    # dataframes for the date\n",
    "    signal_df = data_processor.signal_df_for_date(date)\n",
    "    price_df = data_processor.price_df_for_date(date)\n",
    "\n",
    "    # Update prices to reflect the new values after however much time has passed\n",
    "    # Need to dot his first each date because the updated prices may affect our trading rule\n",
    "    portfolio_db.update_prices(price_df)\n",
    "    \n",
    "    # Ask the trading rule what trades we should make\n",
    "    open_trades_df, close_trades_df = trading_rule.compute_trades(signal_df=signal_df)\n",
    "\n",
    "    # apply dates to trades\n",
    "    open_trades_df.loc[:,'open_datetime'] = date\n",
    "    close_trades_df.loc[:,'close_datetime'] = date\n",
    "\n",
    "    # execute trades\n",
    "    trade_executor.execute_opens(open_trades_df=open_trades_df, price_df=price_df)\n",
    "    trade_executor.execute_closes(close_trades_df=close_trades_df, price_df=price_df)    \n",
    "    \n",
    "    # Record account data for today\n",
    "    portfolio_db.record_account_data(price_df=price_df,datetime=date)\n",
    "    \n",
    "    # Do some fancy output tracking our NAV and margin requirement each day\n",
    "    clear_output(wait=True)\n",
    "    display( np.datetime_as_string(np.datetime64(date), unit='D') + ': ' + str(portfolio_db.current_nav()) + \" | \" + str(portfolio_db.current_margin()))\n",
    "    \n",
    "# Now that the loop is done, tell the statistican to output stats\n",
    "statistican.output_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
